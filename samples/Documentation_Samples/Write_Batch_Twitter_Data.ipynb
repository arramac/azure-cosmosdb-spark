{"cells":[{"cell_type":"code","source":["%scala\n\n// Import Necessary Libraries\nimport org.joda.time._\nimport org.joda.time.format._\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\n// Maps\nval readConfigMap = Map(\n\"Endpoint\" -> \"https://cdbtwitter.documents.azure.com:443/\",\n\"Masterkey\" -> \"AnfVszwZbztwIPLheHScaZXoFa7kbWSoYYf75wttJ5Z502xEbeY6RlwHshRuntMisX5bOUzwKa6JvEX00MJi2w==\",\n\"Database\" -> \"Twitterdb\",\n\"Collection\" -> \"Twittercoll\", \n\"preferredRegions\" -> \"East US\",\n\"SamplingRatio\" -> \"1.0\",\n\"schema_samplesize\" -> \"200000\",\n\"query_custom\" -> \"SELECT c.id, c.created_at, c.user.screen_name, c.user.location, c.text, c.retweet_count, c.entities.hashtags, c.entities.user_mentions, c.favorited, c.source FROM c\"\n)\n\nval writeConfigMap = Map(\n\"Endpoint\" -> \"https://cdbtwitter.documents.azure.com:443/\",\n\"Masterkey\" -> \"AnfVszwZbztwIPLheHScaZXoFa7kbWSoYYf75wttJ5Z502xEbeY6RlwHshRuntMisX5bOUzwKa6JvEX00MJi2w==\",\n\"Database\" -> \"Twitterdb\",\n\"Collection\" -> \"Twittercoll1\",  \n\"preferredRegions\" -> \"East US\",\n\"SamplingRatio\" -> \"1.0\",\n\"schema_samplesize\" -> \"200000\"\n)\n\n// Configs\n// get read\nval readConfig = Config(readConfigMap)\nval tweets = spark.read.cosmosDB(readConfig)\ntweets.createOrReplaceTempView(\"tweets\")\ntweets.cache()\n\n// get write\nval writeConfig = Config(writeConfigMap)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import org.joda.time._\nimport org.joda.time.format._\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\nreadConfigMap: scala.collection.immutable.Map[String,String] = Map(query_custom -&gt; SELECT c.id, c.created_at, c.user.screen_name, c.user.location, c.text, c.retweet_count, c.entities.hashtags, c.entities.user_mentions, c.favorited, c.source FROM c, Collection -&gt; Twittercoll, Endpoint -&gt; https://cdbtwitter.documents.azure.com:443/, Database -&gt; Twitterdb, SamplingRatio -&gt; 1.0, schema_samplesize -&gt; 200000, preferredRegions -&gt; East US, Masterkey -&gt; AnfVszwZbztwIPLheHScaZXoFa7kbWSoYYf75wttJ5Z502xEbeY6RlwHshRuntMisX5bOUzwKa6JvEX00MJi2w==)\nwriteConfigMap: scala.collection.immutable.Map[String,String] = Map(Collection -&gt; Twittercoll1, Endpoint -&gt; https://cdbtwitter.documents.azure.com:443/, Database -&gt; Twitterdb, SamplingRatio -&gt; 1.0, schema_samplesize -&gt; 200000, preferredRegions -&gt; East US, Masterkey -&gt; AnfVszwZbztwIPLheHScaZXoFa7kbWSoYYf75wttJ5Z502xEbeY6RlwHshRuntMisX5bOUzwKa6JvEX00MJi2w==)\nreadConfig: com.microsoft.azure.cosmosdb.spark.config.Config = com.microsoft.azure.cosmosdb.spark.config.ConfigBuilder$$anon$1@e8c4049a\ntweets: org.apache.spark.sql.DataFrame = [created_at: string, favorited: boolean ... 8 more fields]\nwriteConfig: com.microsoft.azure.cosmosdb.spark.config.Config = com.microsoft.azure.cosmosdb.spark.config.ConfigBuilder$$anon$1@5e83d2a0\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["%sql\nselect hashtags.text, count(distinct id) as tweets\nfrom (\nselect \n  explode(hashtags) as hashtags,\n  id\nfrom tweets\n) a\ngroup by hashtags.text\norder by tweets desc\nlimit 10"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>text</th><th>tweets</th></tr></thead><tbody><tr><td>AI</td><td>283</td></tr><tr><td>BigData</td><td>203</td></tr><tr><td>MachineLearning</td><td>198</td></tr><tr><td>DeepLearning</td><td>132</td></tr><tr><td>IoT</td><td>114</td></tr><tr><td>DataScience</td><td>101</td></tr><tr><td>ArtificialIntelligence</td><td>94</td></tr><tr><td>ML</td><td>76</td></tr><tr><td>DL</td><td>57</td></tr><tr><td>Infographics</td><td>56</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["%scala\n// Import SaveMode so you can Overwrite, Append, ErrorIfExists, Ignore\nimport org.apache.spark.sql.{Row, SaveMode, SparkSession}\n\n// Create new DataFrame of tweets tags\nval tweets_bytags = spark.sql(\"select '2018-06-12' as currdt, hashtags.text as hashtags, count(distinct id) as tweets from ( select explode(hashtags) as hashtags, id from tweets ) a group by hashtags.text order by tweets desc limit 10\")\n\n// Save to Cosmos DB (using Append in this case)\n//    Ensure the baseConfig contains a Read-Write Key\n//    The key provided in our examples is a Read-Only Key\n//tweets_bytags.write.mode(SaveMode.Append).cosmosDB(writeConfig)\ntweets_bytags.write.mode(SaveMode.Overwrite).cosmosDB(writeConfig)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import org.apache.spark.sql.{Row, SaveMode, SparkSession}\ntweets_bytags: org.apache.spark.sql.DataFrame = [currdt: string, hashtags: string ... 1 more field]\n</div>"]}}],"execution_count":3}],"metadata":{"name":"Write_Batch_Twitter_Data","notebookId":520817756907437},"nbformat":4,"nbformat_minor":0}
